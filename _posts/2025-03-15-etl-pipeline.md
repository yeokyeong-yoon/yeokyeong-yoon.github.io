---
layout: post
title: "Building Enterprise Data Pipeline Series - Part 1: Data Ingestion with Databricks"
date: 2025-03-15 12:00:00 +0900
categories: Data Engineering
tags: [Data Engineering, Data Ingestion, ETL, Databricks, Distributed Systems, Data Pipeline]
mermaid: true
---

> 이 글은 Enterprise Data Pipeline 구축 시리즈의 첫 번째 파트로, 데이터 수집(Data Ingestion) 파이프라인 구축에 관한 내용입니다. 향후 Transformation, Loading, Operations 등 추가 파트가 이어질 예정입니다.

## 1. 문제 정의 – "데이터 증가에 따른 구조 개선 필요성"

### 1.1 프로젝트 배경

다이나믹 프라이싱 시스템은 B2B 기반의 서비스로, 실시간 시장 상황과 경쟁사 가격을 분석하여 최적의 가격을 결정합니다. 현재는 소수의 파트너사와 협력하고 있으나, 앞으로 더 많은 파트너사들과 함께 서비스 영역을 확장할 계획입니다.

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'fontSize': '16px'}}}%%
graph LR
    subgraph "Dynamic Pricing Solution"
        direction LR
        Data[데이터 수집]
        ML[ML 모델]
        Price[가격 결정]
        Analytics[비즈니스 분석]
    end
    
    Data --> ML
    ML --> Price
    Price --> Analytics
```

### 1.2 기존 시스템의 문제점

초기 데이터 파이프라인은 정제되지 않은 파일을 병합하고 일정한 형식으로 저장하는 단순한 구조였습니다. 하지만 데이터 소스가 증가하고, 처리 주기가 다양해지면서 기존 방식으로는 확장성과 안정성을 확보하기 어려웠습니다. 특히 단일 처리 스크립트 구조는 에러 발생 시 전체 흐름에 영향을 주는 병목 요인이 되었습니다.

주요 문제점:
1. **스키마 종속성**: 레거시 시스템 전용 스키마로 타 파트너사 데이터 재활용 불가
2. **스토리지 비용 상승**: 지속적인 원본 데이터 적재로 관리 비용과 스토리지 비용 증가
3. **비효율적인 인제스트 방식**: 변경 감지 메커니즘 부재로 중복 적재 및 리소스 낭비
4. **DQA 체계 부재**: 실시간/배치 기반 데이터 품질 검증 체계 미흡

## 2. 기존 접근과 한계

### 2.1 초기 구현 시도

기존에는 Spark를 활용해 전체 데이터를 병합 후 저장하는 구조를 사용했습니다. 이 과정에서 `coalesce(1)`을 통한 단일 파일 출력 방식을 택했으나, 데이터 양이 증가하면서 Driver 노드의 메모리 부족 문제가 반복적으로 발생했습니다. 또한, 각 테이블을 순차적으로 처리하는 방식은 배치 시간 증가의 원인이 되었습니다.

### 2.2 데이터 특성과 처리 과제

현재 해외 파트너사로부터 수신하는 데이터는 다음과 같은 특성을 갖고 있습니다:

- **데이터 볼륨**
  - 일일 수만 개의 `.tar.gz` 압축 파일 수신
  - 각 압축 파일은 수백 MB 크기
  - 압축 파일 내부에는 테이블별 `.csv` 파일 다수 포함

- **데이터 스키마**
  - 파일명 패턴: `{table_name}_{date}_{batch_id}.csv` 형식으로 제공
  - 테이블마다 스키마와 컬럼 수가 상이 → 병합시 스키마 불일치 이슈
  - 일부 테이블은 일자별 스키마 변동 가능성으로 다이나믹 스키마 핸들링 필요

## 3. 구조 개선 방향 및 적용

### 3.1 Databricks 환경 도입

Databricks 환경을 도입하여 작업을 테이블 단위로 분산 처리하도록 구조를 변경했습니다. Spark Job을 Task 단위로 분리하고, 각 작업은 독립적으로 수행되도록 설정해 병렬성을 확보했습니다.

### 3.2 Task 분리 아키텍처

파이프라인을 독립적인 Task들로 분리하여 다음과 같은 구조를 구현했습니다:

1. **압축 해제 Task**
   - `.tar.gz` 압축 파일을 S3에 직접 업로드하여 디스크 공간 절약
   - Python의 `tarfile` 라이브러리 활용

2. **병합 Task**
   - 테이블별로 독립적인 병합 작업 수행
   - 각 테이블의 구조 정보를 JSON 파일로 저장해 활용

3. **작업 간 연결 방식**
   - S3 버킷 경로를 통해 간접적으로 연결
   - 각 작업의 독립적 실행과 실패 시 선택적 재실행 가능

### 3.3 Workflow 기반 전환

Task 분리 후, 더 나은 관리와 자동화를 위해 Databricks Workflow로 전환했습니다:

- **Workflow 구성**
  - `pre_set_date`: process_date 파라미터 설정
  - `wait_for_all_sources`: 소스 파일 Readiness 체크
  - `batch_extract`: 압축 해제 및 S3 업로드
  - 각 테이블별 `merge_*` task: 독립적인 병합 작업
  - `merge_summary`: 병합 완료 후 summary.txt 생성
  - `post_merge_check`: 최종 결과 검증

## 4. 적용 후 성과 및 잔여 이슈

### 4.1 성과

파이프라인 재구성 후 전체 배치 처리 시간이 평균 40~60% 감소했으며, 오류 발생률도 유의미하게 감소했습니다. 특히 다음과 같은 개선이 이루어졌습니다:

1. **처리 성능 향상**
   - 테이블별 병렬 처리로 전체 처리 시간 단축
   - 메모리 사용량 최적화로 안정성 향상

2. **운영 효율성 개선**
   - 작업 간 독립성 확보로 장애 복구 용이
   - 모니터링 및 로깅 체계 강화

### 4.2 잔여 이슈

단, 작업 간 의존성이 복잡한 경우 특정 Task 실패가 전체 흐름에 영향을 주는 구조적 한계는 여전히 존재합니다. 이를 위해 추가적인 실패 복구 전략과 모니터링 체계 보완이 필요한 상태입니다.

## 5. 회고 및 향후 계획

### 5.1 배운 점

단순히 기술 스택을 전환하는 것보다, 파이프라인의 구조와 실행 단위를 세분화하는 것이 더 효과적이었습니다. 특히 다음과 같은 점을 배웠습니다:

1. **모듈화의 중요성**
   - 작업을 독립적인 단위로 분리하는 것이 유지보수성 향상에 도움
   - 각 모듈이 하나의 책임만 가지도록 설계하는 것이 중요

2. **장애 복구 전략**
   - 중간 결과물 저장을 통한 선택적 재실행 가능성 확보
   - 실패 시 전체 파이프라인 재시작 대신 해당 단계만 재실행

### 5.2 향후 계획

앞으로는 다음과 같은 방향으로 운영 편의성과 안정성을 향상시킬 예정입니다:

1. **작업 간 의존성 최소화**
   - Task 간 의존성 구조 단순화
   - 실패 시 영향 범위 최소화

2. **실행 모듈화**
   - 공통 기능을 재사용 가능한 모듈로 분리
   - 새로운 파트너사 추가 시 최소한의 코드 변경으로 대응

3. **모니터링 고도화**
   - 실시간 모니터링 시스템 구축
   - 데이터 품질 메트릭 정의 및 추적
   - 대시보드 구축으로 가시성 향상

## 6. 결론

이번 프로젝트에서는 데이터 파이프라인의 첫 단계인 데이터 수집 부분을 구현했습니다. 현재까지 달성한 주요 성과는 있지만, 전체 데이터 파이프라인 관점에서 아직 해결해야 할 과제들이 더 많습니다. 특히 새로운 파트너사들의 데이터가 어떤 형태일지 모르는 상황이라, 지속적인 개선과 학습이 필요할 것으로 보입니다. 일단은 데이터 수집 파이프라인이 동작한다는 것에 의의를 두고, 차근차근 나머지 부분들을 개선해나가면서 더 배워나갈 예정입니다.