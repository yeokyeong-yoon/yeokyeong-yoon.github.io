---
layout: post
title: "실험 플랫폼의 진화: 추천 모델 평가 도구에서 전사적 데이터 기반 의사결정 인프라로"
date: 2025-03-16
categories: [개발, 운영, 개선]
tags: [실험 플랫폼, A/B 테스트, 데이터 기반 의사결정]
---

*참고 : 아래 내용은 사내 테크톡을 준비하면서 정리한 내용입니다.

## 들어가며

데이터 기반 의사결정은 현대 기업의 핵심 경쟁력이 되었습니다. 특히 어느정도 규모가 있는 IT 서비스 기업에서는 A/B 테스트와 같은 실험을 통해 새로운 기능이나 디자인의 효과를 검증하는 것이 일상적인 업무가 되었습니다. 우리 회사에서도 이러한 흐름에 맞춰 실험 플랫폼을 발전시켜 왔습니다. 이 글에서는 실험 플랫폼이 어떻게 단순한 ML 모델 평가 도구에서 전사적 데이터 기반 의사결정 인프라로 진화했는지 그 여정을 공유하고자 합니다. 

## 1. 실험 플랫폼의 발전 과정

### 초기 단계 (2019-2021)

실험 플랫폼은 처음에는 단순한 목적으로 시작했습니다. 2019-2020년에는 추천 팀 내부의 ML 모델 성능 평가를 위한 관리 도구로 출발했습니다. 이 시기에는 추천 및 랭킹 알고리즘 실험을 위한 기본 기능만을 제공했습니다.

2020년에 중요한 전환점이 있었습니다. A/B 테스트 기능이 도입되면서 플랫폼의 성격이 변화하기 시작했습니다. 이를 통해 일반적인 실험 도구로서의 가능성을 보여주었지만, 여전히 용어와 개념은 추천 시스템에 치우쳐 있었습니다.

2021년에는 실험 플랫폼이 독립된 사이트로 분리되면서 더욱 체계적인 실험 관리가 가능해졌습니다. 그러나 이 시기에도 추천 시스템 용어와 일반 실험 용어의 혼재, 레거시 페이지와 새 페이지의 공존으로 인한 혼란이 있었습니다.

### 도약기 (2023)

2023년에 들어서면서 실험 플랫폼은 큰 도약을 이루었습니다. 상반기에는 두 가지 중요한 기능이 추가되었습니다:

1. **실험 분석 페이지**: 실험군 간 효과를 비교 분석할 수 있는 상세 표와 차트를 제공하여 데이터 기반 의사결정을 강화했습니다.
2. **Feature Flag 기능**: 코드 변경 없이 기능을 동적으로 켜고 끌 수 있게 해주는 도구로, Java SDK 개발 및 배포, 피처 플래그 관리 시스템 도입을 통해 릴리즈 리스크를 감소시켰습니다.

2023년 하반기에는 다음과 같은 핵심 기능이 추가되었습니다:

- **글로벌 슬롯팅(실험 홀드아웃)**: 사용자 그룹을 논리적으로 분리하여 여러 실험이 서로 영향을 미치지 않도록 하는 시스템입니다. 이를 통해 실험 간 독립적인 표본 확보가 가능해져 실험 결과의 신뢰성이 크게 향상되었습니다.
- **실험 일정 기능 강화**: 각 실험의 진행 상황과 일정을 명확히 볼 수 있게 하여 실험 관리의 투명성을 높였습니다.
- **UI 디자인 리뉴얼**: 영문으로 작성된 항목들을 알기 쉽게 한글화하고, 모호한 용어들을 명확히 정의하여 사용자 친화적인 환경을 구축했습니다.
- **공식 가이드 문서 발행**: 표준화된 용어와 목적에 따른 실험 설계 방법론을 제공하여 조직 전체의 일관된 이해를 도왔습니다.

## 2. 기존 실험 환경의 문제점과 해결 방안

### 주요 문제점

#### a) 실험 결과의 신뢰성 저하
여러 팀이 일정 조율 없이 동시에 실험을 진행하다 보니 사용자 그룹이 중복되는 현상이 빈번히 발생했습니다. 이로 인해 한 사용자가 여러 실험에 동시에 참여하게 되면서 실험 간 상호 간섭이 일어나 결과가 왜곡되었습니다. 실험 플랫폼 엔지니어인 저희가 아닌 "실험 팀"이나 담당자가 부재하여, 각 실험의 날짜를 조율하거나 실험을 관리하는 역할이 부재하여 팀별로 현재 진행되고 있는 실험과 미래 계획되고 있는 실험들을 고려해 실험 일정을 조율했어야 했는데, 이를 파악하기가 어려웠습니다.

#### b) 용어와 개념의 비일관성
"추천"과 "실험"이라는 두 가지 다른 영역에서 온 용어들이 혼재되어 있었습니다. 예를 들어, UI에는 "실험 영역"이라는 모호한 용어가 남아있었고, 같은 개념이 백엔드에서는 "organization"으로 불리기도 했습니다. 이러한 용어의 불일치는 팀 간 뿐만 아니라, 팀 내부에서 개발을 하는데도 소통을 어렵게 만들었습니다.

#### c) 서로 다른 이해도와 관행
ML 모델 평가 관점에서 만들어진 플랫폼이다 보니, 실험에는 필요하지 않은 설정들이 실험 플랫폼에 남아 있어 학습 곡선을 만들었습니다. 개발 팀들은 A/B 테스트만을 구성하고 싶은데 불필요한 추천 관련 설정들이 많아서 어려움을 겪었습니다.

#### d) 레거시 문제
Deprecated된 실험 플랫폼의 도메인에서 여전히 추천 QA가 진행되는 경우가 있어 서비스를 완전히 중단할 수 없었습니다. 이로 인해 실험이 중복으로 등록되거나 운영되지 않는 문제도 있었습니다.

#### e) 지식의 편중
실험 설정과 결과 분석에 대한 지식이 Data Analyst 조직에 집중되어 있었습니다. PM이나 실험을 진행하고자 하는 팀들은 실험 플랫폼 활용 방법에 대한 이해도가 상대적으로 낮았습니다. 이로 인해 "실험을 어떻게 설계하고 진행해야 하는지"에 관한 문의가 빈번하게 발생했습니다. 

문제는 이러한 지식 전달이 체계적인 방식으로 이루어지지 않았다는 점입니다. 실험 플랫폼을 운영하는 저와 동료 엔지니어가 과거 실험 사례를 비공식적으로 공유하거나, 개별적인 질문에 응대하는 방식으로 운영되었습니다. 이는 조직 전체의 실험 역량 향상을 저해하고, 실험 플랫폼의 효과적인 활용을 어렵게 만드는 요인이 되었습니다.

#### f) 실험 전담팀의 부재
Data 팀 내에 실험 프로젝트는 시니어 엔지니어인 팀장님과 1명과 저를 포함한 주니어 엔지니어 2명이 담당했는데, 팀장님은 여러 책임을 동시에 맡고 있어 실질적으로는 주니어 엔지니어 2명이 실험 플랫폼을 운영해야 했습니다. 리소스 부족으로 "실험 플랫폼"이라는 도구 제공 이상의 역할을 수행하기 어렵고 했습니다.

### 해결 방안

#### 실험 홀드아웃 개념 도입으로 신뢰성 향상

실험 홀드아웃(레이어/버킷)이란 전체 사용자를 논리적 그룹으로 분리하고, 각 실험이 특정 레이어 내에서만 진행되도록 제한하는 방식입니다. 실험 분배에 쓰이는 해싱 위에 해싱을 한번 더 해서, 어떤 버킷에 할당할지 계산하여, 실험 참여 여부를 결정하도록 했습니다. 해싱이란 입력 데이터를 고정된 길이의 값으로 변환하는 과정으로, 사용자 ID와 같은 식별자를 일관된 방식으로 특정 그룹에 할당하는 데 사용됩니다. 이를 통해 한 사용자가 여러 실험에 참여하더라도 실험 간 상호 영향을 차단하여 결과의 신뢰성을 크게 높일 수 있었습니다.

시스템의 정확성을 검증하기 위해 100만 개의 더미 Cognito ID를 생성하여 실제 환경과 유사한 조건에서 사용자 분배 비율을 테스트했습니다. 이를 통해 실험 그룹 간 1% 미만의 분배 편차를 확인하여 시스템의 정확성을 검증할 수 있었습니다.

#### 용어 및 개념 통일, 지식 공유와 사용자 교육 강화

실험 설정과 결과 분석에 대한 지식이 Data Analyst 조직에 집중되어 있던 문제를 해결하기 위해 체계적인 교육 프로그램과 문서화 작업을 진행했습니다. 실험 플랫폼 사용 방법, 실험 설계 원칙, 결과 분석 기법 등에 관한 상세한 가이드 문서를 작성하여 모든 팀이 접근할 수 있도록 했습니다.

표준화된 주요 용어 정의를 통해 모든 팀이 동일한 언어로 소통할 수 있게 했습니다. 예를 들어:

| 이전 용어 | 표준화된 용어 | 정의 |
| --- | --- | --- |
| 실험 영역, Organization, Domain | 실험 영역 | 특정 제품이나 서비스 영역에서 실험을 관리하는 논리적 단위 |
| 세그먼트, 대조군/실험군, Bucket | 실험 그룹 | 실험에서 서로 다른 처리를 받는 사용자 집단 |

실험 리뉴얼 배포 전, 실험 플랫폼 사용 세미나를 개최하여 PM과 개발자들이 직접 리뉴얼된 실험 플랫폼에서 실험을 설계하고 실행할 수 있는 역량을 기를 수 있도록 지원했습니다.

#### 레거시 시스템 통합과 마이그레이션

Deprecated된 실험 플랫폼에서 여전히 특정 팀에서 추천 QA가 진행되는 경우가 있어 서비스를 완전히 중단할 수는 없었습니다. 대신, 다른 팀에서 접속하는 경우 새로운 실험 페이지로 리다이렉트하도록 설정하여 사용자들이 자연스럽게 새 플랫폼으로 이전할 수 있게 했습니다. 이 과정에서 기존 데이터를 손실 없이 새 플랫폼으로 마이그레이션하는 작업도 진행했습니다. 

#### 리소스 제약 하에서의 효율적인 운영

실험 전담팀의 부재와 리소스 부족 문제는 완전히 해결하기 어려웠지만, 제한된 상황에서 최대한의 효율을 내기 위한 여러 방안을 모색했습니다. 배포 freezing 기간에 tech debt를 해결하자고 제안하여, 2주 가량동안 문서화, ci/cd 자동화, 유닛테스트 추가 등 반복적인 업무를 최소화할 수 있는 일을 진행하고, 사용자 셀프 서비스 기능을 강화하여 엔지니어의 개입 없이도 간단한 업무는 별도의 문의 없이 가능하도록 했습니다.

또한, 주요 사용 사례와 모범 사례를 문서화하고 공유함으로써, 제한된 인력으로도 넓은 범위의 사용자 요구를 지원할 수 있게 되었습니다.

## 3. 현재와 미래: 실험 플랫폼의 발전 방향

### 진행 중인 개선사항

#### 실험 분석 강화

현재 진행 중인 핵심 개선 사항 중 하나는 **PKM(Product Key Metrics) 연동**입니다. DA팀과 Y-NEXT팀의 협업을 통해 주요 서비스 지표를 실험 표본별로 조회할 수 있는 기능이 추가되고 있습니다.

또한, 기존의 **베이지안 평가 방식** 외에도 **빈도주의(p-value 평가) 지표**를 추가하여 다양한 관점에서 실험 결과를 분석할 수 있도록 개선하고 있습니다.

베이지안 평가 방식이란 사전 확률과 관측 데이터를 결합하여 사후 확률을 계산하는 통계적 접근법으로, 불확실성을 확률 분포로 표현하고 새로운 데이터가 들어올 때마다 이 분포를 업데이트합니다. 반면 빈도주의 방식은 p-value를 통해 귀무가설(실험이 효과가 없다는 가설)을 기각할 수 있는지 평가하는 전통적인 통계 방법입니다. 두 방식은 상호 보완적이며, 함께 사용할 경우 실험 결과에 대한 더 풍부한 해석이 가능합니다.

#### 사용자 편의성 강화

실험 플랫폼의 접근성과 개발 환경 지원을 확대하기 위해 FE팀과 협력하여 **JavaScript SDK** 를 개발했으며, EKS 환경에서의 효율적인 운영을 지원하는 확장도 계획하고 있습니다.

또한, 기존에 DEV, QA, STAGE, PROD로 분리되어 있던 **실험 플랫폼 웹 페이지를 하나의 통합된 페이지로 개선**하여 운영의 단순화와 관리 효율성을 높일 생각입니다.

이 외에도 다음과 같은 피드백이 있었는데요, 
- 실험 진행 상황을 실험 플랫폼에서 확인하고 싶다.
- 다른 팀에서 진행 중인 실험과 충돌 없이 실험을 운영할 수 있는지 알고 싶다.
- 실험이 처음인 사용자를 위한 가이드 문서가 필요하다.

이러한 요구에 대응하여 **실험 일정 기능 강화, 글로벌 슬롯팅 도입, 공식 가이드 문서 발행** 등의 개선이 이루어졌습니다.

## 4. 향후 발전 방향

### 실험 전담팀 구성의 필요성

현재의 제한된 리소스 상황에서도 다양한 개선이 이루어졌지만, **장기적으로는 실험 전담팀 구성이 필요**하다고 생각합니다. 현재는 주니어 엔지니어 중심의 운영 체제로 인해 도구 제공 이상의 역할을 수행하기 어렵고, 실험 설계 및 결과 해석의 전문성을 확보하는 데 한계가 있습니다.

**PM, 데이터 분석팀, 엔지니어로 구성된 실험 전담팀**이 운영된다면, 다음과 같은 역할을 수행할 수 있을 것입니다:

- **실험 설계 및 컨설팅 지원**: 각 팀이 최적의 실험 방법을 선택할 수 있도록 가이드 제공
- **실험 진행 현황 모니터링**: 실험 진행 중 문제 발생 시 빠른 대응
- **결과 분석 및 인사이트 도출**: 실험 데이터를 활용한 전사적 의사결정 지원
- **실험 문화 확산**: 사내 교육 및 가이드 제공을 통한 데이터 기반 의사결정 문화 조성

## 5. 결론

실험 플랫폼은 추천 ML 모델 평가 도구에서 시작하여, 전사적인 데이터 기반 의사결정을 지원하는 종합 플랫폼으로 발전해왔습니다. 이 과정에서 다양한 도전에 직면했지만, 이를 체계적으로 해결하며 더 강력하고 사용하기 쉬운 실험 환경을 구축했습니다.

앞으로, 실험 플랫폼 서비스와 팀이 확장하게 되다면 실험 플랫폼은 모든 개발 팀이 손쉽게 실험을 수행하고, 서비스 품질을 지속적으로 개선할 수 있는 핵심 인프라로 자리 잡을 것입니다. 앞으로도 실험 플랫폼은 데이터 기반 의사결정 문화를 선도하며, 서비스 성장과 혁신을 지원하는 중요한 역할을 수행할 것입니다.

## 6. 개인적인 소회

실험 플랫폼 개발/운영을 맡으면서 가장 도움이 되었던 것은 의외로 컴퓨터 공학 수업이 아니었습니다. 오히려 대학 시절 경영학 전공으로 들었던 "경영통계학"과 "통계자료분석" 수업이 큰 밑거름이 되었습니다. 그 당시에는 R로 데이터 EDA를 진행하고, 신뢰도를 평가하는 정도였기 때문에 직접적인 적용에는 한계가 있었지만, 그래도 그 수업들을 들었던 덕분에 '실험'이라는 분야에 대한 진입 장벽이 낮았던 것 같습니다.

하지만 솔직히 말하면, 대학 시절에 이론으로만 배우고 시험 치고 나면 잊어버렸던 통계 개념들이 실무에서 다시 마주쳤을 때 생각보다 어려웠습니다. 베이지안 통계, 인과추론, 다변량 분석 같은 개념들이 실제 업무에 적용되니 이해하기가 쉽지 않았고, 실험 결과를 분석하거나 DA팀과 소통할 때 종종 한계를 느꼈습니다. 앞으로 이 분야를 계속 담당하게 된다면 통계학적 지식을 더 깊이 공부해야겠다는 생각이 들었습니다. 기술적인 엔지니어링 역량도 중요하지만, 도메인 전문가로서 통계적 지식까지 갖추었다면 팀 내외에서 더 큰 가치를 만들어낼 수 있었을 텐데 하는 아쉬움과 함께 통계학적 지식을 더 쌓고 싶다는 욕심이 생겼습니다.

A/B 테스트와 실험 플랫폼 분야는 기술과 통계, 비즈니스 이해가 모두 필요한 융합 영역입니다. 실험 플랫폼 인수인계가 결정되고 뒤늦게 블로그를 적기 때문에 하는 말이지만, 다음에 다시 이 분야를 맡게 된다면 단순히 코드를 작성하는 것을 넘어 도메인의 기초 이론과 원리를 이해하는 데도 더 많은 시간을 투자해야겠다는 생각이 들었습니다. 이런 깊이 있는 이해를 바탕으로 할 때 비로소 더 넓은 시야를 가진 엔지니어로 성장할 수 있을 것 같습니다.

## 용어 정리
- **A/B Testing(A/B 테스트)**: 새로운 기능이나 디자인의 효과를 검증하기 위해 사용자 그룹을 나누어 다른 버전을 제공하고 결과를 비교하는 실험 방법
- **Bayesian Evaluation(베이지안 평가 방식)**: 사전 확률과 관측 데이터를 결합하여 사후 확률을 계산하는 통계적 접근법으로, 실험 결과 분석에 활용됨
- **CI/CD(지속적 통합/지속적 배포)**: 코드 변경사항을 자동으로 테스트하고 배포하는 소프트웨어 개발 방법론
- **Data-Driven Decision Making(데이터 기반 의사결정)**: 직관이나 경험이 아닌 데이터 분석 결과를 바탕으로 의사결정을 내리는 접근 방식
- **EKS(Elastic Kubernetes Service)**: AWS에서 제공하는 관리형 쿠버네티스 서비스로, 컨테이너화된 애플리케이션 배포에 사용됨
- **Experiment Holdout(실험 홀드아웃)**: 전체 사용자를 논리적 그룹으로 분리하여 실험 간 상호 영향을 차단하는 방식
- **Feature Flag(피처 플래그)**: 코드 변경 없이 기능을 동적으로 켜고 끌 수 있게 해주는 도구
- **Frequentist Statistics(빈도주의 통계)**: p-value를 통해 귀무가설을 기각할 수 있는지 평가하는 전통적인 통계 방법
- **Hashing(해싱)**: 입력 데이터를 고정된 길이의 값으로 변환하는 과정으로, 사용자를 실험 그룹에 할당하는 데 사용됨
- **Java SDK(Java 소프트웨어 개발 키트)**: Java 언어로 개발된 소프트웨어 개발 도구 모음
- **JavaScript SDK(JavaScript 소프트웨어 개발 키트)**: JavaScript 언어로 개발된 소프트웨어 개발 도구 모음
- **ML Model Evaluation(ML 모델 평가)**: 머신러닝 모델의 성능을 측정하고 검증하는 과정
- **p-value(p값)**: 관측된 결과가 귀무가설 하에서 발생할 확률을 나타내는 통계적 지표
- **PKM(Product Key Metrics)**: 제품의 성과를 측정하는 핵심 지표
- **Recommendation System(추천 시스템)**: 사용자의 선호도나 행동 패턴을 분석하여 관련 콘텐츠나 제품을 추천하는 시스템
- **Slotting(슬롯팅)**: 사용자를 여러 실험 그룹으로 분배하는 방식