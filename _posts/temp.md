# 데이터 엔지니어링 핵심 가이드

## 1. 데이터 엔지니어링 소개

### 1.1 핵심 키워드
- 데이터 엔지니어링 정의
- 현대적 데이터 스택
- 클라우드 기반 아키텍처 (GCP 특화)
- 오픈소스 컴포넌트
- 데이터 성숙도
- 데이터 팀 역할

### 1.2 핵심 내용
- 데이터 엔지니어링은 데이터 수집, 저장, 처리, 분석을 위한 인프라와 파이프라인 구축을 담당
- 현대적 데이터 스택은 데이터 소스, 수집 커넥터, 클라우드 데이터 스토어, BI/시각화로 구성
- GCP 환경에서는 BigQuery, GCS, Dataflow, Pub/Sub 등의 서비스 활용이 중심
- 데이터 엔지니어는 데이터 사이언티스트와 분석가가 효율적으로 작업할 수 있는 환경 구축
- 조직의 데이터 성숙도에 따라 데이터 엔지니어링 전략이 달라짐

### 1.3 준비 중점 영역 (GCP 환경)
- **BigQuery 사용법 및 쿼리 최적화**: 실무에서 가장 빈번하게 사용하는 도구
- **GCP 기본 서비스 이해**: GCS, BigQuery, Pub/Sub, Dataflow, IAM
- **Batch와 Streaming 차이**: Dataflow vs Airflow, Pub/Sub vs Kafka
- **dbt 및 Semantic Layer 구조**: 데이터 모델링 및 의미 기반 데이터 뷰 설계

## 2. 엔드투엔드 데이터 파이프라인 심층 분석

### 2.1 핵심 키워드
- 직렬화(Serialization)
- 저장 포맷(Row-based vs Column-based)
- 압축과 캐싱
- ACID vs BASE
- OLTP vs OLAP
- 데이터 웨어하우스/레이크/레이크하우스
- ETL vs ELT
- 배치/마이크로배치/스트리밍
- 스키마 변경 관리
- 데이터 모델링
- 클릭스트림 수집 및 처리

### 2.2 데이터 직렬화와 저장 포맷
- **Row-based**: XML, JSON, CSV (개별 행 조회에 최적화)
- **Column-based**: Parquet, ORC, Arrow (컬럼 집계 연산에 최적화)
- **GCP 특화**: BigQuery는 Capacitor 컬럼 기반 저장소 활용

### 2.3 압축과 캐싱
- **압축**: 저장 공간 절약, 쿼리 속도 향상, 데이터 전송 효율성 개선
- **캐싱**: 메모리는 SSD보다 1000배 빠르며, 고성능은 비용 증가 수반
- **GCP 특화**: BigQuery 쿼리 결과 캐싱으로 비용 절감

### 2.4 데이터베이스 트랜잭션 특성
- **ACID** (단일 머신): 원자성, 일관성, 격리성, 지속성
- **BASE** (분산 DB): 기본적 가용성, 소프트 상태, 최종 일관성

### 2.5 스토리지 시스템 유형
- **GCP 특화**: GCS(Object Storage), Persistent Disk(Block Storage)
- **File Storage**: 계층적 파일 시스템(로컬, NAS, 클라우드)
- **Block Storage**: HDD/SSD, AWS EBS
- **Object Storage**: GCS
- **Cache Storage**: RAM, Memcached, Redis
- **Streaming Storage**: 실시간 데이터 처리용 버퍼링

### 2.6 데이터 저장소 유형
- **데이터 웨어하우스**: 구조화된 데이터, BigQuery
- **데이터 레이크**: 정형/비정형 데이터, GCS 활용
- **데이터 레이크하우스**: 통합 솔루션, BigLake

### 2.7 데이터 수집(Ingestion)
- **배치**: 일별/시간별 대량 데이터 수집
- **마이크로배치**: 분/초 단위 준실시간 수집
- **스트리밍**: 초 단위 이하 실시간 수집(Pub/Sub, Dataflow)
- **GCP 특화**: 로그 스키마 정의, 파티션 전략 관리, GCS 저장 후 BQ 적재

### 2.8 ETL vs ELT
- **ETL**: 전통적 데이터 웨어하우스에 적합, 사전 처리 후 적재
- **ELT**: 현대적 데이터 레이크하우스에 적합, 적재 후 처리, 더 유연하고 확장성 높음
- **GCP 특화**: BigQuery는 ELT 패턴에 최적화됨

### 2.9 클릭스트림 로그 및 전환 추적 데이터
- 로그 스키마 정의 및 설계 원칙
- JSON 스키마 관리 및 버전 관리
- 파티션 전략 (일자별, 앱별 등)
- 전환 분석을 위한 필수 필드 및 스키마 설계
- 하위호환성 보장 방법

## 3. 기반 요소들

### 3.1 핵심 키워드
- DataOps
- 오케스트레이션
- 데이터 보안/개인정보
- 데이터 품질
- 개발 워크플로우
- 데이터 카탈로그 및 라인에이지 관리

### 3.2 DataOps
- 데이터 시스템에 DevOps 원칙 적용(~DevOps for data)
- 데이터 도구 및 클라우드 인프라 구축 및 관리
- 자동화(CI/CD 포함)로 안정적 배포와 빠른 피드백
- **GCP 특화**: Terraform을 활용한 GCP 리소스 관리, IAM 자동화

### 3.3 오케스트레이션
- 데이터 파이프라인 작업 간 의존성 조정 및 자동화
- **주요 도구**: Dagster, Apache Airflow, Cloud Composer (GCP)
- **Dagster**: 선언적 방식, 로컬 개발 환경 지원, 클라우드 네이티브
- **Apache Airflow**: DAG 기반, 널리 사용되나 설정과 관리가 복잡
- **주요 기능**: retries, retry_delay, TriggerRule, depends_on_past

#### 3.3.1 Airflow 핵심 개념
- **DAG**: 작업 간의 실행 순서를 정의하는 Directed Acyclic Graph
- **Task(Operator)**: 실제 작업 단위
- **Scheduler**: DAG 실행 스케줄링
- **Executor**: 작업 실행 방식 결정

### 3.4 데이터 품질(DQA)
- "Data fails silently" - 코드 변경 없이도 데이터 문제 발생 가능
- **유효성 검사**: 타입, 제약 조건, 코드 검증
- **테스트**: 단위 테스트, 통계적 테스트
- **관측성**: 모니터링, 알림, 스키마 변경 감지, 로깅
- **핵심 검사**: Null check, Type casting, Outlier detection, Business rule validation
- **GCP 특화**: BigQuery Data Quality, Cloud Monitoring

### 3.5 데이터 카탈로그 및 라인에이지
- Data Catalog 또는 자체 Portal을 통한 데이터 소스 간 흐름 정리
- 메타데이터 관리 및 데이터 계보 추적
- OpenLineage, Marquez 같은 오픈소스 도구 활용
- **GCP 특화**: Data Catalog, Dataplex

### 3.6 메시징 시스템 - Kafka/Pub/Sub

#### 3.6.1 Kafka 핵심 개념
- **역할**: 대용량 실시간 메시지 스트리밍 플랫폼
- **구성요소**: Producer, Consumer, Topic, Broker
- **특징**: 메시지 순서 보장(partition), 메시지 유실 방지 설정 가능 (acks, replication)
- **활용 예시**: 사용자 활동 로그 수집, 실시간 지표 전송

#### 3.6.2 Kafka에서 메시지 유실 방지 방법
- 메시지 복제(replication) 설정
- acks=all 설정으로 모든 복제본에 쓰기 완료 확인
- Consumer offset commit 제어
- 적절한 Consumer Group 구성
- 재시도 정책 및 DLQ(Dead Letter Queue) 구현

## 4. 데이터 파이프라인 아키텍처 예시

### 4.1 핵심 키워드
- BI 스택
- 스트리밍 스택
- ML/AI 스택
- Semantic Layer
- 사내 데이터 포털
- dbt

### 4.2 좋은 데이터 아키텍처 특성
- 성능, 확장성, 안정성, 장애 예측
- 보안, 모듈화, 비용 효율성, 유연성

### 4.3 GCP 기반 데이터 파이프라인
- **수집**: Pub/Sub, Dataflow
- **저장**: GCS, BigQuery
- **처리**: Dataflow, BigQuery
- **서빙**: Looker, Data Studio

### 4.4 Semantic Layer 설계
- dbt, Looker 등으로 의미 기반 데이터 뷰 설계
- 쿼리 사용자 관점의 데이터 모델 설계
- 비즈니스 로직의 중앙화 및 재사용성 향상

### 4.5 스트리밍 스택
- **GCP 특화**: Pub/Sub → Dataflow → BigQuery 파이프라인
- 상태 관리, 정확성 보장(exactly-once) 설계
- 윈도우 처리 및 지연 데이터 핸들링

### 4.6 Storage 설계
- **GCP 특화**: GCS + Parquet + BigQuery 파티셔닝
- 파티션 전략(일자별, 앱별)
- 성능 개선: 클러스터링, 파티션 프루닝, 쿼리 최적화

### 4.7 dbt (Data Build Tool)
- **역할**: SQL 기반 데이터 모델링 및 ELT 자동화
- **특징**: SQL 쿼리로 테이블 모델을 선언하고 dependency 관리 가능
- **구성요소**: model, snapshot, seed, test, run
- **활용 예시**: BigQuery에서 raw_orders를 기반으로 fact_orders 생성, 테스트 및 문서화 포함

### 4.8 GCP 환경 특화 파이프라인 사례

#### 4.8.1 클릭스트림 수집 및 처리 파이프라인
- **소스**: 웹/앱 이벤트
- **수집**: Pub/Sub
- **처리**: Dataflow
- **저장**: GCS(raw) → BigQuery(processed)
- **관리**: JSON 스키마 레지스트리, 파티션 전략

#### 4.8.2 재무/제품 분석용 배치 파이프라인
- **소스**: 운영 DB, 외부 시스템
- **수집**: Cloud Composer(Airflow) DAG
- **저장**: BigQuery
- **변환**: dbt로 비즈니스 모델 구축
- **서빙**: Looker 대시보드

#### 4.8.3 마케팅 전환 추적 시스템
- **소스**: 클릭스트림, CRM 데이터
- **처리**: BigQuery ELT
- **모델링**: 사용자 여정 및 전환 경로 분석
- **서빙**: 마케팅 분석 대시보드

## 5. 필수 기술 및 실무 준비

### 5.1 핵심 키워드
- SQL (BigQuery SQL)
- Python
- GCP 서비스
- dbt
- Terraform
- JSON Schema

### 5.2 핵심 내용
- **SQL**: BigQuery SQL 최적화 기법, 복잡한 분석 쿼리 작성 능력
- **Python**: 데이터 처리 및 자동화, Dataflow 파이프라인 개발
- **GCP 서비스**: BigQuery, GCS, Pub/Sub, Dataflow, IAM 등
- **dbt**: 데이터 모델링 및 변환 로직 정의
- **Terraform**: Infrastructure as Code, GCP 리소스 관리
- **JSON Schema**: 로그 스키마 정의 및 버전 관리

### 5.3 주니어 역할 대비 실무 태스크
- **배치 파이프라인 유지/운영**: 재무, 제품 분석용 데이터 파이프라인을 GCP(BigQuery) 기반으로 운용
- **클릭스트림 수집 및 처리**: 로그 스키마 정의, 파티션 전략 관리, GCS에 저장 후 BQ 적재
- **카탈로그 문서화 및 라인에이지 관리**: Data Catalog 또는 자체 Portal을 통한 데이터 흐름 정리
- **전환 추적 데이터 집계**: Marketing 전환 분석 쿼리, 지표 산출용 ETL 테이블 생성
- **로그 스키마 관리**: JSON schema 정의, 버전 관리 방식 적용

### 5.4 중장기 성장 트랙
- **Semantic Layer 설계**: dbt, Looker 등으로 의미 기반 데이터 뷰 설계
- **데이터 라인에이지 시스템 개발**: OpenLineage, Marquez 도입/개선
- **스트리밍 파이프라인 설계 및 최적화**: GCP Pub/Sub → Dataflow → BigQuery
- **로그 스키마 및 버전 관리 시스템 설계**: JSON schema registry, backward compatibility
- **사내 데이터 포털 구축**: Lineage, 카탈로그, 메타데이터 관리
- **Terraform + IAM 자동화**: 접근권한, 리소스 정의를 코드 기반으로 관리

## 인터뷰 예상 문제 및 모범 답안

### 데이터 파이프라인 기본 개념

### ETL과 ELT의 차이점은 무엇인가요?

**답변:**

- **ETL(Extract, Transform, Load)**: 데이터를 추출하여 변환한 후 저장하는 전통적 방식
- **ELT(Extract, Load, Transform)**: 데이터를 저장한 후 변환하는 현대적 방식

**추가 설명:**

- ELT는 BigQuery, Snowflake 등 강력한 쿼리 처리 성능을 가진 데이터 웨어하우스를 활용
- ELT는 원본 데이터를 보존하여 유연성이 높고 재처리가 용이함
- 현대 클라우드 환경에서는 ELT가 더 높은 확장성과 비용 효율성을 제공

### Batch와 Streaming 처리의 차이와 적절한 사용 사례는?

**답변:**

- **Batch 처리**: 데이터를 일정 기간 동안 모아서 처리하며, 지연이 허용되는 경우에 적합
- **Streaming 처리**: 데이터가 발생하는 즉시 처리하며, 낮은 지연 시간이 요구되는 경우에 적합

**적합한 상황:**

- **Batch**: 일별 재무 보고서, 주간 마케팅 분석, 대규모 데이터 학습
- **Streaming**: 실시간 알림, 부정 거래 탐지, 실시간 대시보드, 사용자 행동 추적

### 데이터 웨어하우스와 데이터 레이크의 차이점은?

**답변:**

| 항목 | 데이터 레이크 | 데이터 웨어하우스 |
| --- | --- | --- |
| 스키마 | Schema-on-Read (읽을 때 구조화) | Schema-on-Write (쓸 때 구조화) |
| 데이터 유형 | 정형/비정형 모두 저장 가능 | 주로 정형 데이터 중심 |
| 주요 도구 | S3, GCS, Delta Lake | BigQuery, Redshift, Snowflake |
| 사용 사례 | ML 학습, 원본 데이터 보관 | BI 리포팅, 정형 분석 |
| 비용 | 저장 비용 상대적 저렴 | 쿼리 처리 비용 상대적 높음 |
| 유연성 | 매우 높음 | 제한적 |

### 데이터 레이크하우스는 무엇이며 장점은?

**답변:**

- 데이터 레이크와 데이터 웨어하우스의 장점을 결합한 하이브리드 아키텍처
- 주요 구현체: Apache Iceberg, Delta Lake, Apache Hudi

**장점:**

- 저비용 객체 스토리지를 활용하면서 고성능 SQL 쿼리 제공
- ACID 트랜잭션 지원
- 스키마 진화 관리
- 정형/비정형 데이터 통합 처리
- 컴퓨팅과 스토리지의 독립적 확장 가능

### 메시징 및 스트리밍 시스템

### Kafka에서 메시지 유실을 방지하려면 어떻게 해야 하나요?

**답변:**

- **Producer 측**:
    - `acks=all` 설정으로 모든 복제본에 쓰기 완료 확인
    - `retries` 옵션 설정으로 전송 실패 시 재시도
    - `enable.idempotence=true`로 중복 방지
- **Broker 측**:
    - `replication.factor` ≥ 2로 설정하여 데이터 복제
    - `min.insync.replicas` 설정으로 최소 복제본 수 지정
- **Consumer 측**:
    - `auto.commit.enable=false`로 설정하고 수동 커밋
    - 처리 성공 후에만 오프셋 커밋

### Kafka의 partition 개수는 어떻게 결정하나요?

**답변:**

- 결정 요소:
    - 처리량: 파티션 수가 많을수록 병렬 처리 가능
    - 소비자 그룹의 크기: 파티션 수가 최대 병렬 소비자 수 결정
    - 메시지 순서: 파티션 내에서만 순서 보장
    - 리소스 사용량: 파티션이 많을수록 더 많은 리소스 필요
- 가이드라인:
    - 토픽당 6-10개 파티션으로 시작
    - 필요 파티션 수 = (목표 처리량) ÷ (단일 파티션 처리량)
    - 브로커 수의 약 3배 정도로 시작하는 것이 일반적

### Kafka에서 exactly-once 처리를 보장하려면 어떻게 해야 하나요?

**답변:**

- Kafka 0.11 이상에서 제공되는 Transactional API 사용
- **Producer 설정**:
    - `enable.idempotence=true`
    - 고유한 `transactional.id` 설정
    - `initTransaction() → send() → commitTransaction()` 흐름으로 구현
- **Consumer 설정**:
    - `isolation.level=read_committed` 설정
    - 처리 결과와 오프셋을 동일 트랜잭션에 저장
- **Kafka Streams**:
    - `processing.guarantee=exactly_once_v2` 설정 (Kafka 2.5+)

### 워크플로우 오케스트레이션

### Airflow의 DAG이란 무엇인가요?

**답변:**

- DAG(Directed Acyclic Graph)는 작업(task)의 실행 순서를 정의하는 방향성 비순환 그래프
- 각 Task는 PythonOperator, BashOperator 등 다양한 Operator로 구성
- 주요 속성:
    - `schedule_interval`: 실행 주기
    - `start_date`: 시작 날짜
    - `depends_on_past`: 이전 실행 결과에 따른 의존성
    - `retries`: 실패 시 재시도 횟수
    - `trigger_rule`: 의존 태스크 완료 조건 (all_success, one_success 등)

### Airflow에서 Task가 실패했을 때 재처리는 어떻게 설정하나요?

**답변:**

```python
# 태스크 수준 재시도 설정
task = PythonOperator(
    task_id='process_data',
    python_callable=process_function,
    retries=3,  # 최대 3회 재시도
    retry_delay=timedelta(minutes=5),  # 5분 간격으로 재시도
    retry_exponential_backoff=True,  # 지수 백오프 적용
    max_retry_delay=timedelta(minutes=30)  # 최대 지연 시간
)

# 실패 콜백 설정
def failure_handler(context):
    # Slack 알림 등 실패 처리 로직
    send_slack_alert(context['task_instance'])

task = PythonOperator(
    task_id='critical_task',
    python_callable=process_function,
    on_failure_callback=failure_handler
)

```

### Spark와 Airflow의 역할 차이는?

**답변:**

- **Spark**는 데이터 처리(연산) 엔진
    - 대규모 데이터 배치 및 스트림 처리 수행
    - 분산 컴퓨팅 환경에서 데이터 변환 및 분석
    - SQL, DataFrame, RDD API 제공
- **Airflow**는 워크플로우 오케스트레이션 도구
    - 여러 작업 간의 의존성 및 실행 순서 관리
    - 스케줄링, 모니터링, 에러 처리 기능
    - 다양한 시스템과의 통합 (Spark, BigQuery, Redshift 등)

**예시**: Airflow는 매일 9시에 Spark Job을 실행하고, 완료되면 결과를 이메일로 보내는 워크플로우를 조정

### 데이터 모델링 및 변환

### dbt 모델 간 의존성은 어떻게 정의하나요?

**답변:**

- **ref 함수** 사용(가장 일반적):
    
    ```sql
    SELECT * FROM {{ ref('upstream_model') }}
    
    ```
    
- **source 함수** (원본 데이터 참조):
    
    ```sql
    SELECT * FROM {{ source('schema_name', 'table_name') }}
    
    ```
    
- dbt는 이러한 참조를 통해 자동으로 의존성 DAG 구성
- `dbt docs generate` 명령으로 의존성 시각화 가능
- 의존성에 따라 최적의 실행 순서 자동 결정

### 데이터 모델링 방법론 중 Kimball, Inmon, Data Vault의 차이점은?

**답변:**

- **Kimball(차원 모델링)**:
    - 비즈니스 프로세스 중심, 스타 스키마
    - 사용자 친화적이고 쿼리 성능이 우수
    - 점진적 개발 가능, 유연한 변경
- **Inmon(기업 데이터 웨어하우스)**:
    - 주제 중심, 높은 정규화
    - 엔터프라이즈 전체 일관성 보장
    - 하향식 접근법, 초기 투자 비용 높음
- **Data Vault**:
    - Hub(핵심 비즈니스 개체), Link(관계), Satellite(속성) 구조
    - 유연성과 확장성이 뛰어남
    - 역사적 추적에 강점, 복잡한 구현

### Wide Tables vs 정규화 테이블의 장단점은?

**답변:**

- **Wide Tables(비정규화)**:
    - **장점**: 조인 없이 빠른 분석 쿼리, 구현 단순
    - **단점**: 데이터 중복, 스토리지 효율성 저하, 일관성 유지 어려움
    - **적합 사례**: 분석 워크로드, 자주 변경되지 않는 데이터
- **정규화 테이블**:
    - **장점**: 중복 제거, 데이터 일관성, 업데이트 효율
    - **단점**: 조인 필요로 쿼리 복잡성 증가, 성능 저하 가능
    - **적합 사례**: 트랜잭션 워크로드, 빈번한 업데이트
- 현대 데이터 웨어하우스와 컬럼형 저장소는 비정규화 모델의 단점을 완화
- 종종 하이브리드 접근 방식(적절한 비정규화 + 스타 스키마)이 실용적

### 데이터베이스 및 저장소

### OLTP와 OLAP의 차이점은 무엇인가요?

**답변:**

| 특성 | OLTP | OLAP |
| --- | --- | --- |
| 주요 목적 | 트랜잭션 처리 | 분석 및 의사결정 |
| 데이터 모델 | Row-based, 정규화 | Column-based, 비정규화 |
| 쿼 |  |  |

**데이터 엔지니어링 인터뷰 준비 완벽 가이드**

**데이터베이스 및 저장소**

**OLTP와 OLAP의 차이점은 무엇인가요?**

**답변:**

특성 | OLTP | OLAP  
--- | --- | ---  
쿼리 패턴 | 단순, 소량 레코드 접근 | 복잡, 대량 데이터 집계  
업데이트 | 빈번, 작은 트랜잭션 | 드물고 대규모 배치  
성능 지표 | 낮은 지연 시간 | 높은 처리량  
예시 | PostgreSQL, MySQL | BigQuery, Snowflake  
사용 사례 | 웹 앱, 주문 처리 | 비즈니스 인텔리전스, 분석  

**Snowflake와 Redshift의 차이점은 무엇인가요?**

**답변:**

• **아키텍처**:  
    ◦ Snowflake: 컴퓨팅과 스토리지 완전 분리, 멀티 클러스터  
    ◦ Redshift: 컴퓨팅과 스토리지 더 긴밀하게 연결, 단일 클러스터  

• **확장성**:  
    ◦ Snowflake: 즉시 자동 확장/축소, 웨어하우스 개념  
    ◦ Redshift: 수동 확장, 확장 시간 소요, RA3 노드로 일부 개선  

• **가격 모델**:  
    ◦ Snowflake: 사용량 기반, 초 단위 청구  
    ◦ Redshift: 노드 기반, 시간 단위(온디맨드) 또는 예약 인스턴스  

• **데이터 공유**:  
    ◦ Snowflake: 네이티브 데이터 공유 기능, 마켓플레이스  
    ◦ Redshift: AWS 데이터 공유로 제한적 지원  

• **관리 편의성**:  
    ◦ Snowflake: 거의 관리 필요 없음, 자동 클러스터링  
    ◦ Redshift: VACUUM, ANALYZE 등 관리 작업 필요  

**ClickHouse의 장점과 적합한 워크로드는?**

**답변:**

• **장점**:  
    ◦ 컬럼 기반 스토리지로 분석 쿼리 고성능  
    ◦ 높은 압축률(10배 이상)로 스토리지 효율성  
    ◦ 초당 수십억 행 처리 가능한 높은 삽입 속도  
    ◦ 다양한 집계 함수와 병렬 처리 최적화  
    ◦ 실시간 분석에 최적화된 낮은 지연 시간  

• **적합한 워크로드**:  
    ◦ 시계열 데이터 분석(로그, 이벤트, 지표)  
    ◦ OLAP 워크로드, 데이터 마트  
    ◦ 실시간 대시보드 및 분석  
    ◦ 청구 및 금융 분석  
    ◦ 적합하지 않음: OLTP, 빈번한 단일 행 업데이트  

**시스템 설계 및 아키텍처**

**Lambda 아키텍처와 Kappa 아키텍처의 차이는?**

**답변:**

• **Lambda 아키텍처**:  
    ◦ **구조**: 배치 레이어(정확성) + 스피드 레이어(실시간성) + 서빙 레이어(통합)  
    ◦ **장점**: 정확성과 실시간성 모두 확보  
    ◦ **단점**: 코드 중복, 운영 복잡성, 일관성 유지 어려움  
    ◦ **적합**: 높은 정확성 필요, 기존 배치 시스템 활용 시  

• **Kappa 아키텍처**:  
    ◦ **구조**: 단일 스트림 처리 레이어 + 필요시 로그 재처리  
    ◦ **장점**: 단순한 코드베이스, 운영 간소화  
    ◦ **단점**: 복잡한 스트림 처리 로직, 대용량 처리 도전적  
    ◦ **적합**: 단순성 우선, 실시간 중심, 재처리 가능한 시스템  

**데이터 파이프라인을 처음 설계한다면 어떤 것을 고려할 건가요?**

**답변:**

1. **비즈니스 요구사항 파악**:  
    ◦ 데이터 신선도 요구사항(실시간 vs 배치)  
    ◦ SLA(서비스 수준 계약) 요구사항  
    ◦ 확장성 요구사항(현재 및 예상 데이터 볼륨)  

2. **데이터 특성 분석**:  
    ◦ 데이터 소스 유형 및 형식(구조화, 반구조화, 비구조화)  
    ◦ 데이터 크기 및 성장률  
    ◦ 데이터 품질 및 일관성 요구사항  

3. **기술 스택 선택**:  
    ◦ 수집: Kafka/Pub-Sub, Airflow, Fivetran 등  
    ◦ 저장: S3/GCS, BigQuery, Snowflake 등  
    ◦ 처리: Spark, Flink, dbt 등  
    ◦ 서빙: BI 도구, API, ML 모델 등  

4. **아키텍처 설계 결정**:  
    ◦ ETL vs ELT  
    ◦ 배치 vs 스트리밍 vs 하이브리드  
    ◦ 스케일 업 vs 스케일 아웃  

5. **운영 고려사항**:  
    ◦ 모니터링 및 알림  
    ◦ 데이터 품질 검증  
    ◦ 장애 복구 전략  
    ◦ 보안 및 규정 준수  

**스트리밍 파이프라인과 배치 파이프라인의 병렬성 차이를 설명해주세요.**

**답변:**

• **배치 파이프라인 병렬성**:  
    ◦ 정적 파티셔닝: 파일, 날짜 범위 등으로 명시적 분할  
    ◦ 고정 자원 할당: 처리 시작 전 계획  
    ◦ 균등 분배: 데이터 크기에 따라 균형 조정 가능  
    ◦ 재시도: 전체 또는 분할 단위로 재실행  
    ◦ 도구: Spark, Hadoop MapReduce  

• **스트리밍 파이프라인 병렬성**:  
    ◦ 동적 분할: 메시지 키, 파티션 기반 실시간 분배  
    ◦ 탄력적 자원: 부하에 따라 자동 조정  
    ◦ 데이터 스큐: 키 분포 불균형 발생 가능  
    ◦ 연속 처리: 중단 없는 이벤트 흐름  
    ◦ 상태 관리: 윈도우, 체크포인트 필요  
    ◦ 도구: Kafka Streams, Flink, Spark Streaming  

**문제 해결 및 디버깅**

**실시간 지표 대시보드가 느리게 업데이트됩니다. 어떻게 디버깅하시겠어요?**

**답변:**

1. **데이터 흐름 전체 매핑**:  
    ◦ 소스 → 수집 → 처리 → 저장 → 시각화 경로 확인  

2. **각 구간 지연시간 측정**:  
    ◦ 소스 시스템: 이벤트 생성 지연  
    ◦ 메시지 브로커: Kafka/Pub-Sub 지연, 파티션 불균형  
    ◦ 스트림 처리: 윈도우 설정, 버퍼링 지연  
    ◦ 저장소: 쓰기 병목, 인덱스 부재  
    ◦ 쿼리: 비효율적 쿼리, 캐싱 부재  
    ◦ UI: 렌더링 지연, 폴링 간격  

3. **최적화 전략**:  
    ◦ 파이프라인 병렬화 확대  
    ◦ 사전 집계 도입  
    ◦ 중간 캐싱 계층 추가  
    ◦ 데이터베이스 인덱싱 최적화  
    ◦ 쿼리 최적화 및 간소화  

**Kafka consumer가 계속 offset을 잃어버린다면 어떤 문제일까요?**

**답변:**

• **가능한 원인**:  
    1. **Consumer 그룹 ID 불일치**: 의도치 않게 그룹 ID 변경  
    2. **세션 타임아웃 설정 부적절**: `session.timeout.ms`가 너무 짧음  
    3. **처리 지연**: `max.poll.interval.ms`보다 처리 시간이 김  
    4. **오프셋 커밋 누락**: 자동 커밋 비활성화 상태에서 수동 커밋 누락  
    5. **리밸런싱 과다**: Consumer 추가/제거 빈번  
    6. **브로커 연결 문제**: 네트워크 불안정, Zookeeper 이슈  

• **해결 방안**:  
    1. Consumer 그룹 ID 일관성 유지  
    2. 적절한 타임아웃 설정(30초 이상)  
    3. 처리 간격 증가 또는 배치 크기 축소  
    4. 명시적 커밋 추가  
    5. 리밸런싱 전략 최적화(`cooperative`)  
    6. 네트워크 및 브로커 상태 점검  

**ETL 도중 컬럼 이름이 예고 없이 변경되면 어떻게 대응하시겠어요?**

**답변:**

• **단기 대응**:  
    1. **유연한 스키마 처리**:  
        ▪ 열 이름 매핑 레이어 추가  
        ▪ 스키마 진화 메커니즘 활용(Avro, Protobuf)  

    2. **임시 방어 로직**:  
        ▪ 누락 컬럼 감지 및 로깅  
        ▪ 이전/새 컬럼명 모두 시도하는 fallback 로직  

• **장기 대응**:  
    1. **스키마 관리 시스템 도입**:  
        ▪ 스키마 레지스트리 구축  
        ▪ 변경 감지 및 알림 시스템  

    2. **업스트림 팀과 협업**:  
        ▪ 스키마 변경 프로세스 합의  
        ▪ 변경 전 알림 체계 구축  

    3. **파이프라인 강화**:  
        ▪ 스키마 자동 검증 단계 추가  
        ▪ 데이터 계약 개념 도입  

**Spark에서 OOM(Out of Memory)이 자주 발생합니다. 어떻게 해결하시겠어요?**

**답변:**

1. **메모리 설정 최적화**:  
    ◦ `spark.executor.memory` 증가  
    ◦ `spark.driver.memory` 검토  
    ◦ `spark.memory.fraction` 조정  
    ◦ `spark.memory.storageFraction` 검토  

2. **데이터 처리 패턴 개선**:  
    ◦ `collect()` 대신 `take()`/`limit()` 사용  
    ◦ `groupByKey` 대신 `reduceByKey` 사용  
    ◦ 불필요한 셔플 연산 제거  
    ◦ 파티션 수 최적화  

3. **캐싱 전략 점검**:  
    ◦ 불필요한 캐싱 제거  
    ◦ `MEMORY_AND_DISK` 저장 레벨 사용  
    ◦ 사용 완료 후 `unpersist()` 호출  

4. **데이터 스큐 해결**:  
    ◦ 키 분포 분석  
    ◦ Salting 기법 적용  
    ◦ 브로드캐스트 조인 활용(작은 테이블)  

5. **모니터링 및 진단**:  
    ◦ Spark UI 활용  
    ◦ GC 로그 분석  
    ◦ Stage별 메모리 사용량 프로파일링  

**한 테이블에 중복 레코드가 주기적으로 발생한다면 어떻게 방지하시겠어요?**

**답변:**

1. **소스 레벨 방지**:  
    ◦ 중복 이벤트 발생 원인 파악  
    ◦ 고유 이벤트 ID 생성 및 전파  
    ◦ 소스 시스템에 멱등성 로직 구현  

2. **수집 단계 방지**:  
    ◦ CDC(변경 데이터 캡처) 사용 시 중복 탐지  
    ◦ 메시징 시스템에서 중복 제거  
    ◦ 트랜잭션 ID/체크섬 활용  

3. **처리 단계 중복 제거**:  
    ◦ 윈도우 기반 중복 제거 로직  
    ◦ 상태 저장소 활용한 처리 기록  
    ◦ Spark `dropDuplicates()` 활용  

4. **로드 단계 방지**:  
    ◦ 데이터베이스 고유 제약 조건  
    ◦ UPSERT 패턴 적용(MERGE INTO)  
    ◦ 복합 키 또는 해시 키 사용  

5. **모니터링 및 경고**:  
    ◦ 중복 발생 지표 모니터링  
    ◦ 임계값 초과 시 알림  
    ◦ 정기적 감사 쿼리 실행  

**경험 부족 시 대응 예시**

"Kafka 직접 써본 경험 있으신가요?"

**답변:**  
"실무에서 Kafka를 직접 운영해보진 않았지만, Pub/Sub 구조와 메시지 브로커의 개념은 충분히 이해하고 있습니다. 특히 메시지 유실 방지, Consumer 그룹 구조, 파티션 기반 병렬 처리 원리에 대해 학습했습니다. 최근에는 로컬 환경에서 Python Consumer/Producer 코드를 작성해보며 실습했고, 필요하다면 실무에서 빠르게 적용할 수 있습니다."

**"데이터 파이프라인을 구축해본 경험 있으신가요?"**

**답변:**  
"대규모 압축 파일의 병합 및 테이블별 분할 처리를 위한 파이프라인을 직접 설계하고 운영해본 경험이 있습니다. 이 과정에서 ETL 전체 흐름(수집 → 처리 → 저장)을 경험했으며, NULL 값 체크, 파일 개수 기반 병렬 처리, 병목 테이블 분리 등 실무적 문제를 해결했습니다. 이러한 경험을 바탕으로 GCP 환경의 데이터 파이프라인 구축에 빠르게 적응할 수 있을 것으로 생각합니다."

**"Airflow 써보셨나요?"**

**답변:**  
"Airflow의 기본 개념인 DAG, Operator, Executor, Scheduler에 대한 이해가 있으며, 재시도 설정, 의존성 관리, 실패 복구 전략과 같은 중요 기능들을 학습했습니다. Cloud Composer가 GCP의 관리형 Airflow 서비스라는 것도 알고 있어, GCP 환경에서 워크플로우 오케스트레이션을 수행하는데 필요한 지식을 갖추고 있습니다. 실무에서 빠르게 적응하여 데이터 파이프라인의 스케줄링과 의존성 관리를 효과적으로 수행할 자신이 있습니다."

**ETL 파이프라인 SLA 및 운영**

**ETL 파이프라인에서 SLA 보장 설계는 어떻게 하시겠어요?**

**답변:**

1. **SLA 정의 및 지표 설정**:  
    ◦ 완료 시간 목표(예: 매일 오전 8시까지 완료)  
    ◦ 데이터 신선도 요구사항(예: 최대 6시간 지연)  
    ◦ 허용 가능한 실패율(예: 월간 99.5% 성공률)  
    ◦ 복구 시간 목표(RTO)(예: 장애 발생 후 1시간 내 복구)  

2. **모니터링 체계 구축**:  
    ◦ 실행 시간 및 진행 상황 추적  
    ◦ 단계별 완료율 모니터링  
    ◦ 리소스 사용량 모니터링(CPU, 메모리, I/O)  
    ◦ 조기 경고 시스템 구축(예상 완료 시간 초과 시)  

3. **실패 처리 설계**:  
    ◦ 자동 재시도 메커니즘(지수 백오프 적용)  
    ◦ 장애 격리(한 단계 실패가 전체에 영향 최소화)  
    ◦ 부분 성공 처리 로직(가능한 부분은 계속 진행)  
    ◦ 우아한 성능 저하(degradation) 전략  

4. **스케줄링 최적화**:  
    ◦ 크리티컬 패스 분석 및 최적화  
    ◦ 병렬 처리 최대화  
    ◦ 의존성 최소화 또는 재구성  
    ◦ 우선순위 기반 자원 할당  

5. **비상 계획 수립**:  
    ◦ 에스컬레이션 프로세스 정의  
    ◦ 수동 개입 절차 문서화  
    ◦ 데이터 복구 메커니즘 구현  
    ◦ 롤백 및 대체 흐름 설계  

**Daily batch job이 실패해서 어제 리포트가 비었습니다. DAG 재실행 전에 검증할 체크포인트는 무엇인가요?**

**답변:**

1. **장애 원인 파악**:  
    ◦ Airflow 로그 검토로 정확한 실패 지점과 에러 메시지 확인  
    ◦ 업스트림 데이터 소스 가용성 확인  
    ◦ 리소스 제약(메모리, 디스크 공간) 문제 확인  
    ◦ 권한 또는 인증 이슈 확인  

2. **데이터 상태 검증**:  
    ◦ 소스 데이터 존재 및 완전성 확인  
    ◦ 부분적으로 처리된 데이터 식별  
    ◦ 복원 지점(checkpoint) 확인  
    ◦ 기존 대상 테이블의 무결성 검증  

3. **재실행 영향 분석**:  
    ◦ 멱등성 확인(재실행이 중복 데이터를 생성하지 않는지)  
    ◦ 다운스트림 의존성 파악(이미 실행된 후속 작업이 있는지)  
    ◦ 데이터 일관성 보장 방안 수립  

4. **실행 전략 수립**:  
    ◦ 전체 DAG vs 실패 태스크부터 재실행  
    ◦ 병렬 처리 최적화 설정  
    ◦ 필요시 수동 데이터 복구 절차 계획  
    ◦ 완료 후 검증 계획 수립  

**Airflow DAG이 종종 random하게 실패합니다. 원인 분석 절차를 설명해주세요.**

**답변:**

1. **패턴 분석**:  
    ◦ 특정 시간대/요일 패턴 확인(부하 집중 시간대)  
    ◦ 특정 태스크에 집중된 실패인지 확인  
    ◦ 다른 DAG 실행과의 상관관계 분석  

2. **리소스 검사**:  
    ◦ Worker 노드 메모리/CPU 사용량 분석  
    ◦ 디스크 공간 및 I/O 병목 확인  
    ◦ 데이터베이스 연결 풀 상태 점검  
    ◦ 네트워크 대역폭 및 지연 시간 모니터링  

3. **시스템 의존성 검사**:  
    ◦ 외부 서비스 응답 시간 및 가용성 확인  
    ◦ 데이터베이스 성능 및 연결 상태 검사  
    ◦ API 종속성 안정성 및 응답 시간 점검  

4. **코드 및 구성 검토**:  
    ◦ 예외 처리 부족한 부분 식별  
    ◦ 타임아웃 설정 검토  
    ◦ 경쟁 조건(race condition) 가능성 검사  
    ◦ 메모리 누수 가능성 확인  

5. **개선 방안 구현**:  
    ◦ 로깅 강화로 상세 진단 정보 확보  
    ◦ 중요 태스크의 재시도 메커니즘 강화  
    ◦ 리소스 할당 최적화  
    ◦ 큰 태스크 분할하여 리스크 분산  
    ◦ 모니터링 및 알림 개선  

**데이터 품질 관리**

**데이터 품질 테스트를 자동화하려면 어떤 전략을 사용하시겠어요?**

**답변:**

1. **품질 규칙 정의**:  
    ◦ 완전성(null 값, 누락 레코드)  
    ◦ 정확성(유효 범위, 형식)  
    ◦ 일관성(관계 규칙, 기준 데이터 일치)  
    ◦ 시의성(최신성, 지연 시간)  
    ◦ 유일성(중복 데이터)  

2. **테스트 자동화 도구 선택**:  
    ◦ dbt test(SQL 기반 테스트)  
    ◦ Great Expectations(Python 기반)  
    ◦ Apache Griffin(빅데이터 품질)  
    ◦ Soda SQL/Cloud(SQL 기반 검증)  

3. **파이프라인 통합 포인트**:  
    ◦ 소스 데이터 수집 전 검증  
    ◦ 변환 후 중간 결과 검증  
    ◦ 최종 로드 전/후 검증  
    ◦ 주기적 레거시 데이터 검증  

4. **모니터링 및 알림 시스템**:  
    ◦ 임계값 기반 알림  
    ◦ 트렌드 모니터링(점진적 악화 감지)  
    ◦ 이상 탐지 기법 적용  
    ◦ 실패 심각도별 알림 차별화  

5. **CI/CD 통합**:  
    ◦ 파이프라인 배포 전 품질 테스트 자동화  
    ◦ 실패 시 자동 롤백 메커니즘  
    ◦ 품질 게이트 설정(최소 기준 미달 시 진행 불가)  

6. **품질 메트릭 대시보드**:  
    ◦ 품질 점수 시각화  
    ◦ 시간에 따른 추이 분석  
    ◦ 문제 영역 강조 및 분류  

**A팀의 BigQuery 테이블에 정의서가 없고 최근 컬럼이 변경된 것 같은데, lineage로 추적이 가능할까요?**

**답변:**  
"네, 데이터 라인에이지를 활용하여 변경사항을 추적할 수 있습니다. 다음과 같은 접근 방법을 사용하겠습니다:

1. **BigQuery 메타데이터 분석**:  
    ◦ `INFORMATION_SCHEMA.COLUMNS` 쿼리로 현재 스키마 확인  
    ◦ 테이블 버전 히스토리 조회(가능한 경우)  
    ◦ 최근 스키마 변경 시점 파악  

2. **자동화된 라인에이지 도구 활용**:  
    ◦ Data Catalog API 사용하여 메타데이터 검색  
    ◦ 테이블 종속성 및 상위/하위 관계 확인  
    ◦ OpenLineage/Marquez와 같은 도구 활용(구축된 경우)  

3. **쿼리 히스토리 분석**:  
    ◦ BigQuery 감사 로그에서 DDL 문 검색  
    ◦ 테이블 생성/변경 쿼리 식별  
    ◦ 작업 수행한 사용자 및 시간 확인  

4. **하위 영향 분석**:  
    ◦ 해당 테이블을 참조하는 다운스트림 작업 식별  
    ◦ 잠재적 영향 받는 대시보드/보고서 파악  
    ◦ 문제 발생 가능성 있는 ETL 작업 확인  

5. **해결 방안**:  
    ◦ A팀과 협업하여 변경 내용 문서화  
    ◦ 스키마 변경 관리 프로세스 제안  
    ◦ 자동화된 스키마 문서화 도구 도입 검토"  

**데이터 품질 문제를 겪은 경험이 있으신가요?**

**답변 예시:**  
"네, 이전 프로젝트에서 주요 데이터 파이프라인의 품질 문제를 해결한 경험이 있습니다. 고객 행동 분석 파이프라인에서 갑자기 전환율 지표가 40% 하락하는 이상 현상이 발생했습니다.

**문제 분석 과정**:  
1. 먼저 데이터 흐름을 역추적하여 사용자 활동 로그부터 최종 보고서까지 각 단계를 검사했습니다.  
2. 모바일 앱 버전 업데이트와 일치하는 시점에 이벤트 로그 형식이 변경되었음을 발견했습니다.  
3. 특히 'action_completed' 필드가 기존 Boolean에서 String 타입으로 변경되어 파싱 에러가 발생했습니다.  

**해결 방안**:  
1. 단기적으로 파서 로직을 수정하여 두 형식 모두 처리 가능하게 했습니다.  
2. 누락된 데이터는 백필링을 통해 복구했습니다.  
3. 장기적 해결책으로 스키마 검증 단계를 추가하고, 앱 개발팀과 데이터팀 간 변경 관리 프로세스를 수립했습니다.  
4. 자동화된 데이터 품질 모니터링 시스템을 도입하여 유사 문제를 조기 감지할 수 있도록 했습니다.  

이 경험을 통해 선제적 데이터 품질 관리의 중요성을 깨달았고, 이후 프로젝트에서는 항상 스키마 진화 관리와 데이터 계약 개념을 도입하여 유사 문제를 방지하고 있습니다."

### 시간대 및 특수 데이터 처리 

### 시간대(Timezone)가 혼합된 로그 데이터를 처리할 때 주의할 점은 무엇인가요?

**답변:**

1. **표준화된 저장 전략**:
    - 모든 타임스탬프를 UTC로 변환하여 저장
    - 원본 타임존 정보 별도 보존(필요시)
    - ISO 8601 형식 사용(예: "2023-04-10T15:30:00Z")
2. **타임존 인식 파싱**:
    - 입력 타임스탬프의 타임존 명시적 처리
    - 다양한 입력 형식 지원(ISO, UNIX 타임스탬프 등)
    - 일광 절약 시간(DST) 변환 고려
3. **분석 시 고려사항**:
    - 집계 시 일관된 시간대 사용
    - 날짜 경계 문제 주의(자정 기준 집계 등)
    - 주/월/분기 경계에서의 특별 처리
4. **비즈니스 요구사항 반영**:
    - 보고서 목적의 타임존 결정(현지 시간 vs 표준 시간)
    - 지역별 분석 필요성 고려
    - 사용자 기준 시간 개인화 요구사항 반영
5. **시간 기반 작업 조정**:
    - ETL 스케줄링에 타임존 고려
    - 글로벌 서비스의 경우 피크 시간 분산
    - 배치 윈도우 설정 시 타임존 불일치 주의
6. **개발 및 디버깅 지원**:
    - 원본 타임스탬프 보존으로 추적성 확보
    - 타임존 변환 과정 로깅
    - 테스트 케이스에 다양한 타임존 시나리오 포함

## 데이터 시스템 설계 예시

### 실시간 트레이딩 데이터를 수집하고 분석 가능한 구조로 만드는 시스템을 설계해보세요.

**답변:1. 데이터 수집 계층**:

- 트레이딩 API로부터 이벤트 수집(거래, 호가, 주문 등)
- Kafka를 메시지 브로커로 활용(토픽: trades, orders, quotes)
- 고가용성 및 내구성을 위한 멀티 브로커 설정
- Producer 측 acks=all, 적절한 파티션 설정으로 처리량 최적화

**2. 처리 계층**:

- **실시간 처리**: Kafka → Flink/KStreams
    - 5초 단위 이동 윈도우로 집계(최소/최대/거래량)
    - 이상 패턴 실시간 탐지(급등락, 비정상 거래량)
    - CEP(Complex Event Processing) 패턴 적용
- **배치 처리**: 일별 요약 및 심층 분석
    - Spark로 복잡한 집계 및 추세 분석
    - 일별/주별/월별 OHLCV 계산

**3. 저장 계층**:

- **핫 데이터**(최근): ClickHouse 또는 TimescaleDB
    - 실시간 조회 및 분석 최적화
    - 고성능 시계열 쿼리 지원
- **웜 데이터**(중기): BigQuery/Snowflake
    - SQL 기반 복잡한 분석 지원
    - BI 도구 통합
- **콜드 데이터**(장기): 객체 스토리지(GCS/S3) + Parquet
    - 비용 효율적 장기 보관
    - 필요시 쿼리 가능한 형태 유지

**4. 서빙 계층**:

- REST API 및 WebSocket 인터페이스 제공
- Looker/Tableau 등 BI 도구 연동
- 사용자 알림 서비스(Kafka → 알림 서비스)

**5. 운영 고려사항**:

- 멱등성 있는 처리로 중복 방지
- 모니터링 및 알림(지연 시간, 처리량, 에러율)
- 데이터 정합성 검증 및 복구 전략
- 확장성을 위한 수평적 스케일링 설계

### 거래 시스템 로그를 활용해 사용자별 위험 스코어를 계산해야 합니다. 어떻게 파이프라인을 설계하시겠어요?

**답변:1. 데이터 수집**:

- 거래 API 및 로그 시스템에서 이벤트 추출
- Kafka 토픽 구성: user_activity, risk_events, transactions
- CDC(Change Data Capture)로 관련 DB 변경사항 수집

**2. 데이터 전처리**:

- **배치 처리**: Spark로 일일 위험 지표 계산
    - 사용자별 행동 패턴 분석
    - 히스토리컬 데이터 기반 이상치 탐지
    - 거래 빈도, 금액, 지역, 시간대 등 특성 추출
- **실시간 처리**: Flink로 실시간 위험 신호 탐지
    - 연속된 실패 시도, 비정상적 접근 패턴
    - 지리적 이상(빠른 위치 변경 등)
    - 슬라이딩 윈도우로 최근 행동 분석

**3. 스코어링 모델**:

- 가중치 기반 규칙 엔진(초기 구현)
- ML 모델 적용(Random Forest, XGBoost 등)
- 정기적인 모델 재학습 및 평가

**4. 저장 및 서빙**:

- BigQuery/Snowflake에 risk_score_by_user 테이블 생성
- Redis에 실시간 위험 점수 캐싱(빠른 조회)
- 위험 점수 API 서비스(gRPC/REST)
- 위험 관리 대시보드(Looker/Tableau)

**5. 오케스트레이션 및 품질 관리**:

- Airflow로 배치 작업 관리
- dbt로 변환 로직 및 테스트 자동화
- 품질 검증 및 모니터링
- 위험 점수 이상치 알림

**6. 개인정보 보호 및 보안**:

- 민감 데이터 암호화 및 접근 제어
- PII 데이터 익명화 또는 마스킹
- 감사 로그 및 접근 내역 기록

이러한 종합적인 접근을 통해 실시간 및 배치 기반 위험 스코어링 시스템을 구축하고, 지속적인 개선과 모니터링을 수행할 수 있습니다.

## 용어 해설

- **데이터 파이프라인 (Data Pipeline):** 데이터를 한 시스템에서 다른 시스템으로 이동시키고 변환하는 과정의 자동화된 흐름.
- **ETL (Extract, Transform, Load):** 다양한 소스에서 데이터를 추출(Extract)하고, 분석에 적합한 형태로 변환(Transform)한 후, 데이터 웨어하우스 등의 저장소에 적재(Load)하는 과정.
- **ELT (Extract, Load, Transform):** 데이터를 먼저 저장소에 적재(Load)한 후, 필요에 따라 저장소 내에서 변환(Transform)하는 방식.
- **데이터 웨어하우스 (Data Warehouse):** 보고 및 분석 목적으로 설계된, 다양한 소스로부터 통합된 정형 데이터의 중앙 집중식 저장소.
- **데이터 레이크 (Data Lake):** 정형, 비정형, 반정형 등 다양한 형태의 데이터를 원래 형식으로 저장할 수 있는 대규모 저장소.
- **데이터 레이크하우스 (Data Lakehouse):** 데이터 레이크와 데이터 웨어하우스의 장점을 결합한 새로운 데이터 관리 아키텍처.
- **OLTP (Online Transaction Processing):** 실시간 트랜잭션 처리에 최적화된 데이터베이스 시스템.
- **OLAP (Online Analytical Processing):** 복잡한 분석 쿼리 처리에 최적화된 데이터베이스 시스템.
- **정규화 (Normalization):** 데이터베이스 설계 시 데이터 중복을 최소화하고 데이터 무결성을 확보하기 위한 과정.
- **비정규화 (Denormalization):** 쿼리 성능 향상을 위해 의도적으로 데이터 중복을 허용하는 데이터베이스 설계 기법.
- **스키마 (Schema):** 데이터베이스의 구조와 제약 조건을 정의하는 청사진.
- **ACID (Atomicity, Consistency, Isolation, Durability):** 트랜잭션 데이터베이스의 네 가지 주요 속성.
- **BASE (Basically Available, Soft-state, Eventually consistent):** 분산 시스템에서 일관성 대신 가용성을 우선시하는 모델.
- **데이터 수집 (Ingestion):** 다양한 데이터 소스에서 데이터를 시스템으로 가져오는 과정.
- **배치 처리 (Batch Processing):** 일정 주기에 따라 데이터를 묶어서 처리하는 방식.
- **스트리밍 처리 (Streaming Processing):** 데이터가 생성되는 즉시 실시간으로 처리하는 방식.
- **데이터 모델링 (Data Modeling):** 비즈니스 요구사항을 기반으로 데이터베이스의 구조를 설계하는 과정.
- **데이터 거버넌스 (Data Governance):** 데이터의 품질, 보안, 개인 정보 보호 등을 관리하기 위한 정책 및 프로세스.
- **데이터 품질 (Data Quality):** 데이터의 정확성, 완전성, 일관성, 적시성, 유효성 등을 평가하는 기준.
- **데이터 과학 (Data Science):** 통계학, 컴퓨터 과학, 도메인 지식을 융합하여 데이터로부터 유용한 정보를 추출하는 학문 분야.
- **머신러닝 (Machine Learning):** 명시적인 프로그래밍 없이 컴퓨터가 학습할 수 있도록 하는 알고리즘 및 기술.
- **딥러닝 (Deep Learning):** 여러 계층으로 구성된 신경망을 사용하여 복잡한 패턴을 학습하는 머신러닝의 한 분야.
- **BI (Business Intelligence):** 기업의 의사 결정을 지원하기 위해 데이터를 수집, 분석, 보고하는 과정 및 시스템.
- **데이터옵스 (DataOps):** 데이터 파이프라인의 개발, 배포, 운영을 효율화하기 위한 방법론 및 기술.
- **CI/CD (Continuous Integration/Continuous Deployment):** 소프트웨어 개발 및 배포 과정을 자동화하여 변경 사항을 빠르고 안정적으로 적용하는 방식.
- **특징 저장소 (Feature Store):** 머신러닝 모델 학습 및 추론에 사용되는 특징 데이터를 관리하고 제공하는 중앙 집중식 저장소.
- **람다 아키텍처 (Lambda Architecture):** 배치 처리 계층과 스트림 처리 계층을 결합하여 실시간 및 배치 분석을 모두 지원하는 데이터 처리 아키텍처.
- **카파 아키텍처 (Kappa Architecture):** 스트림 처리만을 사용하여 실시간 데이터 처리 및 재처리를 수행하는 데이터 처리 아키텍처.
- **MPP (Massively Parallel Processing):** 대규모 병렬 처리를 통해 대용량 데이터를 효율적으로 처리하는 기술.
- **NoSQL (Not Only SQL):** 관계형 데이터베이스가 아닌 다양한 유형의 데이터 저장 및 검색 메커니즘을 제공하는 데이터베이스.
- **SQL (Structured Query Language):** 관계형 데이터베이스를 관리하고 쿼리하기 위한 표준 언어.
- **API (Application Programming Interface):** 서로 다른 소프트웨어 애플리케이션이 통신하고 데이터를 교환할 수 있도록 하는 인터페이스.
- **최종 일관성 (Eventual Consistency):** 분산 시스템에서 업데이트가 모든 노드에 즉시 반영되지 않더라도, 시간이 지나면 결국 모든 노드의 데이터가 일관된 상태로 수렴되는 속성.
- **수직적 스케일링 (Vertical Scaling):** 단일 서버의 하드웨어 자원(CPU, RAM 등)을 늘려 성능을 향상시키는 방식.
- **수평적 스케일링 (Horizontal Scaling):** 여러 서버를 추가하여 시스템의 전체 처리 능력을 확장하는 방식.
- **DataOps:** 데이터 엔지니어링 프로세스에 DevOps 원칙을 적용하여 효율성, 품질, 속도를 향상시키는 방법론.
- **멱등성 (Idempotency):** 동일한 작업을 여러 번 수행하더라도 결과가 한 번 수행했을 때와 동일하도록 보장하는 속성.